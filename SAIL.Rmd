---
title: "SAIL"
name: "Stellen Li"
output: html_document
date: "2022-12-23"
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(readr, pacman, dplyr, ggplot2, tidyr, rio, BMA, png, corrplot, tidyverse, glmnet, Metrics, Hmisc)

data <- read.csv("~/Desktop/Sophomore/Applications/UNC Sports Analysis and Intelligence Laboratory (SAIL)/Dataset/cbb.csv")
```

```{r}
#Adjusted efficiency (ADJOE - ADJDE)
data <- data %>% mutate(ADJE = ADJOE - ADJDE) %>%
  relocate(ADJE, .after = "ADJDE")

#Past NCAA Champions
top_teams <- filter(data, POSTSEASON == "Champions")
top_teams #notice Connecticut has the lowest num of wins and ADJE, could mean that they did reallyyy well during the tournament

#Teams that made it into the March Madness Tournament
bubble_teams <- filter(data, SEED != "NA")
bubble_teams

#Teams that missed the cutoff for the tournament
no_bubble_teams <- filter(data, is.na(SEED)) 
no_bubble_teams
```

```{r}
#Which variables can most accurately predict the rankings of teams?

#ensure that data pass a test of homoscedasticity--are the variances homogeneous?
#conduct t-test to check the features differences between bubble and and non-bubble teams (alpha = 0.1)
var.test(no_bubble_teams$W, bubble_teams$W)
t.test(no_bubble_teams$W, bubble_teams$W, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - more wins

var.test(no_bubble_teams$ADJOE, bubble_teams$ADJOE)
t.test(no_bubble_teams$ADJOE, bubble_teams$ADJOE, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - higher ADJOE

var.test(no_bubble_teams$ADJDE, bubble_teams$ADJDE)
t.test(no_bubble_teams$ADJDE, bubble_teams$ADJDE, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - lower ADJDE

var.test(no_bubble_teams$ADJE, bubble_teams$ADJE)
t.test(no_bubble_teams$ADJE, bubble_teams$ADJE, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - higher ADJE

var.test(no_bubble_teams$BARTHAG, bubble_teams$BARTHAG)
t.test(no_bubble_teams$BARTHAG, bubble_teams$BARTHAG, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - higher BARTHAG

var.test(no_bubble_teams$EFG_O, bubble_teams$EFG_O)
t.test(no_bubble_teams$EFG_O, bubble_teams$EFG_O, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - higher EFG_O

var.test(no_bubble_teams$EFG_D, bubble_teams$EFG_D)
t.test(no_bubble_teams$EFG_D, bubble_teams$EFG_D, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - lower EFG_D

var.test(no_bubble_teams$TOR, bubble_teams$TOR)
t.test(no_bubble_teams$TOR, bubble_teams$TOR, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - lower TOR

var.test(no_bubble_teams$TORD, bubble_teams$TORD)
t.test(no_bubble_teams$TORD, bubble_teams$TORD, var.equal = FALSE)
#reject the null hypothesis (p < 0.0003356) and bubble teams - higher TORD

var.test(no_bubble_teams$ORB, bubble_teams$ORB)
t.test(no_bubble_teams$ORB, bubble_teams$ORB, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - higher ORB

var.test(no_bubble_teams$DRB, bubble_teams$DRB)
t.test(no_bubble_teams$DRB, bubble_teams$DRB, var.equal = FALSE)
#reject the null hypothesis (p < 2.2e-16) and bubble teams - higher DRB

var.test(no_bubble_teams$FTR, bubble_teams$FTR)
t.test(no_bubble_teams$FTR, bubble_teams$FTR, var.equal = FALSE)
#reject the null hypothesis (p < 2.565e-07) and bubble teams - higher FTR

var.test(no_bubble_teams$FTRD, bubble_teams$FTRD)
t.test(no_bubble_teams$FTRD, bubble_teams$FTRD, var.equal = FALSE)
#reject the null hypothesis (p < 2.565e-07) and bubble teams - lower FTRD
```

```{r}
data
numeric_data <- data %>% select(G:WAB, YEAR)
res <- cor(numeric_data)
corrplot(res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
ggplot(data, mapping = aes( x = ADJE, y = W)) +
  geom_point()

#Turnover Percentage Committed (Steal Rate), Free Throw Rate (How often the given team shoots Free Throws), Offensive Rebound Rate, and adjusted tempo are not closely related to the number of wins a team gets
```
```{r}
data <- data %>% mutate(W_percent = W/G) %>% 
  relocate(W_percent, .after = W)
```

```{r}
#Remove categorical variables 
final_data <- data %>%
  select(-c(TEAM, CONF, G, W))

#Convert postseason results into quantitative variables
postseason <- as.vector(data[, "POSTSEASON"])
for (i in 1:length(postseason)) {
  if(is.na(postseason[i]) == TRUE){
    postseason[i] <- 100
  } else if(postseason[i] == '2ND'){
    postseason[i] <- 2
  } else if(postseason[i] == "Champions"){
    postseason[i] = 1
  } else if(postseason[i] == "E8"){
    postseason[i] = 8
  } else if(postseason[i] == "F4"){
    postseason[i] = 4
  } else if(postseason[i] == "R32"){
    postseason[i] = 32
  } else if(postseason[i] == "R64"){
    postseason[i] = 64
  } else if(postseason[i] == "R68"){
    postseason[i] = 68
  } else if(postseason[i] == "S16"){
    postseason[i] = 16
  }
}
postseason. <- as.numeric(postseason)
final_data <- final_data %>% 
  select(-c(POSTSEASON)) %>%
  mutate(postseason.)
final_data
```


```{r}
#Which variables can most accurately predict a team's postseason ranking?
#First use Backward Elimination
lmod <- lm(postseason.~., data = final_data)
summary(lmod) #remove 3P_O

lmod <- update(lmod, .~. -X3P_O)
summary(lmod) #remove YEAR

lmod <- update(lmod, .~. -YEAR)
summary(lmod) #remove EFG_D

lmod <- update(lmod, .~. -EFG_D)
summary(lmod) #remove FTR_D

lmod <- update(lmod, .~. -FTRD)
summary(lmod) #remove ADJ_T

lmod <- update(lmod, .~. -ADJ_T)
summary(lmod) #remove SEED

lmod <- update(lmod, .~. -SEED)
summary(lmod) #remove 2P_D

lmod <- update(lmod, .~. -X2P_O)
summary(lmod) #remove 2P_D

lmod <- update(lmod, .~. -X2P_D)
summary(lmod) #remove ORB

lmod <- update(lmod, .~. -ORB)
summary(lmod) #remove 3P_D

lmod <- update(lmod, .~. -X3P_D)
summary(lmod) #remove TORD

lmod <- update(lmod, .~. -TORD)
summary(lmod) #remove EFG_O

lmod <- update(lmod, .~. -EFG_O)
summary(lmod) #remove TOR

lmod <- update(lmod, .~. -TOR)
summary(lmod) #remove 

#postseason = -8.23366 + 22.07952*W_percent - 3.08449*ADJOE + 2.99657*ADJDE + 151.82153*BARTHAG - 0.3915*DRB + 0.20143*FTR - 3.17840*WAB
```

```{r}
#first perform a lasso regression
#Select W_percent, ADJOE, ADJDE, BARTHAG, DRB, FTR, and WAB based on the variables found to be important using backward selection
trainx_matrix <- select(final_data, W_percent, ADJOE, ADJDE, ADJE, BARTHAG, DRB, FTR, WAB)

#Partition the data into testing and training datasets with an 80-20 split
trainx <- trainx_matrix[1:1964,]
trainy <- final_data$postseason.[1:1964]
testx <- trainx_matrix[1964:2455,]
testy <- final_data$postseason.[1964:2455]

#default alpha = 1
fit = glmnet(trainx, trainy)
plot(fit)

cvfit<-cv.glmnet(as.matrix(trainx), trainy, nfolds = 10) #10 folds is chosen because train data set is relatively large compared to the test data set 
cvfit$lambda.min
which(fit$lambda == cvfit$lambda.min)

coef(cvfit, s = "lambda.min")

cvfit$cvm
cvfit$lambda.min

s = cvfit$lambda.min
lasso_pred = predict(fit, s = s, newx = data.matrix(testx))
rmse(testy, lasso_pred)
#An extremely high rmse (35.75834) shows that Lasso Regression is not preferable in this problem
```
```{r}
#A mixture of Lasso and Ridge by setting alpha = 0.2
fit = glmnet(trainx,trainy, alpha = 0.2)
cvfit = cv.glmnet(as.matrix(trainx),trainy, alpha = 0.2, nfolds = 10)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")

s = cvfit$lambda.min
mixture_pred = predict(fit, s = s, newx = as.matrix(testx))
rmse(testy, mixture_pred)
#rmse is still extremely high (35.75839), so we will try using a pure Ridge model
```
```{r}
#Perform a Ridge Regression
fit = glmnet(trainx,trainy, alpha = 0)
cvfit = cv.glmnet(as.matrix(trainx),trainy, alpha = 0, nfolds = 10)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")

s = cvfit$lambda.min
ridge_pred = predict(fit, s = s, newx = as.matrix(testx))
rmse(testy, ridge_pred)
#RMSE of 36.59133
```
